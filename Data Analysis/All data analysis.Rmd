---
title: "A collective analysis for 126 simulations"
author: "Ranvir Singh Virk "
output:
  pdf_document:
    includes:
      in_header: header.tex
date: "2023-11-14"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(GGally)
library(dtwclust)
library(dplyr)
library(readr)
library(patchwork)
library(gridExtra)
```

## Loading and joining the data

Since we have our data in 126 different files, we will be joining it in
one csv and pre-processing the data to work with.

Let's have a **process_file** function that takes the file and file_id
as inputs and returns data after doing the following conversions for
us:\newline - Set's file_number for each file \newline - Convert the
time from seconds to year \newline - Convert the calcite to avg_calcite
(Averaging out the calcite values for first where value for soln is
between 1 to 10) \newline - Convert the values mole/liter to ton CO2/Ha
\newline

```{r, echo = TRUE}
# Create a funtion to prepocess and join all the files
process_file <- function(file, file_id){
  file_number <- str_extract(file, "(?<=/)[^/]+(?=\\.out$)") # Extracting the file number
  data <- read.table(file, header = TRUE) |>
    filter(state == "transp") |> # Get the files which have state as transp
    mutate(year = time/(3600*24*365)) |> # Convert form sec to year
    rename(`C(4)` = "C.4.") |>
    select(c('soln', 'Calcite', 'Sr', 'C(4)', 'year')) |>
    group_by(year) |>
    mutate(avg_calcite = ifelse(soln %in% 1:10, mean(Calcite[soln %in% 1:10]), Calcite)) |> # Getting the average value for Calcite
    ungroup() |>
    # Conversions from mole/liter to CO2/Ha
    mutate(Calcite = avg_calcite,
           Calcite = Calcite * 500000 * 44 / 1000000 / ifelse(soln %in% 1:10, 1, 10),
           `C(4)` = `C(4)` * 500000 * 44 / 1000000 / 10,
           file_id = file_id) |>
    select(-avg_calcite)
  return(data)
}
```

\newpage

Now that we have this function to process the files, let's read and
combine all the files we have

```{r, echo = TRUE}
# Seting the base path for alljobs directory 
base_path <- "../Data/alljobs" 

# Getting all the simulation folders from the base directory 
folders <- list.dirs(path = base_path, full.names = TRUE, recursive = FALSE)

all_data <- list()

file_counter <- 1

for (folder in folders) {
  # Adjust the pattern to match your .out files, if they have a specific naming convention
  file_paths <- list.files(path = folder, full.names = TRUE, pattern = "*.out$")
  data <- process_file(file_paths, file_counter)
  all_data <- bind_rows(all_data, data)
  file_counter <- file_counter + 1
}

```

```{r}
write.csv(all_data, "./all_data.csv")
```


## Get the data for Total CO2 Capture

We will be partitioning the data in 3 different variables for calcite,
total_capture and the data where the value for soln = 11 \newline The
Calcite and soln_11_data will help us get the total_capture data
required for the Total_CO2_Capture graphs.

```{r, echo = TRUE}
# So let's get the data where the soln value is 11
# We remove the Sr column as we do not need the Sr data for total CO2 caputre data. 
soln_11_data <- all_data |>
  filter(soln == 11) |>
  group_by(file_id)|>
  mutate(`C(4)` = cumsum(`C(4)`)) |>
  ungroup()|>
  dplyr::select(-"Sr") 

calcite <- all_data |>
  filter(soln %in% 1:10) |>
  dplyr::select(-"Sr")


# Now we can use the claclite and soln_11_data to create the total_capture data that we need to plot for the 126 files.
total_capture <- full_join(calcite, soln_11_data, by = c("year", "file_id"), suffix = c(".soil", ".effluent")) |>
  mutate(Total_CO2_capture = Calcite.soil + `C(4).effluent` + Calcite.effluent) |>
  filter(soln.soil == 1) |>
  dplyr::select(c(Total_CO2_capture, year, file_id))
```

```{r}
total_capture <- drop_na(total_capture)
```

\newpage

## Plots

Let's take a look at the plot for total co2 capture for the 126 files
separately.

```{r, fig.width=12, fig.height= 12}
p1 <- ggplot(total_capture, aes(x = year, y = Total_CO2_capture, group = file_id, color = as.factor(file_id))) +
  geom_line(show.legend = FALSE) +  # Set show.legend to FALSE to avoid overcrowding with legend
  labs(title = "Total CO2 Capture for Each File Over Time",
       x = "Year",
       y = "Total CO2 Capture (tonnes CO2/ha)") +
  theme_minimal() +
  theme(legend.position = "none")  # Remove legend

selected_file_ids <- seq(1, 126, by = 10)

# Filter the data for the selected file IDs
selected_data <- total_capture %>%
  filter(file_id %in% selected_file_ids)

# Plotting smoothed lines for selected files
p2 <- ggplot(selected_data, aes(x = year, y = Total_CO2_capture, group = file_id, color = as.factor(file_id))) +
  geom_smooth(se = FALSE, method = "loess") +   # Add smoothed trend lines
  scale_color_viridis_d(option = "C") +          # Use a color scale that prints well in black and white
  labs(title = "Total CO2 Capture Over Time for Selected Files",
       x = "Year",
       y = "Total CO2 Capture (tonnes CO2/ha)",
       color = "File ID") +
  scale_color_viridis_d() +
  theme_minimal()

p1
```

We can see a trend where the Total CO2 Capture is increasing rapidly for
about 0.3 years, and then slows down giving us a elbow shaped curve.

Let's also take a look at an graph for mean values of Calcite,
Bicarbonate and Total CO2 Capture.

```{r, fig.width=12, fig.height= 8}
summary_CO2_data <- total_capture |>
  group_by(year) |>
  summarise(
    mean_CO2_capture = mean(Total_CO2_capture)
  ) |>
  ungroup()

summary_calcite_data <- calcite |> 
  group_by(year) |>
  summarise(
    mean_calcite_capture = mean(Calcite)
  ) |>
  ungroup()

summary_effluent <- soln_11_data |>
  group_by(year) |>
  summarise(
    mean_c4_capture = mean(`C(4)`),
    mean_effluent_calcite_capture = mean(Calcite)
  ) |>
  ungroup()
  

# Plotting with mean and confidence intervals
ggplot() +
  geom_smooth(aes(x = year, y = mean_CO2_capture, color = "Mean CO2 capture"), se = F, data = summary_CO2_data) +
  geom_smooth(aes(x = year, y = mean_calcite_capture, color = "Mean Soil Calcite"), se = F, data = summary_calcite_data) +
  geom_smooth(aes(x = year, y = mean_c4_capture + mean_effluent_calcite_capture, color = "Mean Effluent Calcite + Bicarbonate"), se = F, data = summary_effluent) +
  labs(title = "Average Total CO2 Capture Over Time",
       x = "Year",
       y = "Total CO2 Capture (tonnes CO2/ha)") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

There seems to be a relation between the Mean CO2 Capture and the Mean
Effluent Calcite + Bicarbonate. Although a somewhat reverse relation
between CO2 Capture and Mean Soil Calcite

## IPCC like diagram

We need to group these files on similarity and get the mean values of
those groups. \newline

#### K-Means

We can use the clustering techniques, cluster refers to a collection of
data points, aggregated together based on certain similarity metrics.
For clustering we define a target number k, which is the number of
centroids we want for the dataset. A centroid is the imaginary or real
location representing the center of the cluster. \newline

Let's start with K-mean clustering due to it's simplicity and
scale-ability.

K-means clustering: K means finds the cetroid through the mean or
averaging data points. And then allocating the closest data points to
the nearest cluster.

To determine the appropriate number of clusters, we will need to use the
elbow method. \newline What elbow method does is, plots the graph for
the **"Within Cluster Sum of Squares"**(WCSS), i.e. sum of the square
distance between points in a cluster and the cluster centroid, for
values of k from 1 to n.

For our case let's try with n = 10, so we will be getting the WCSS
values from 1 to 10, and will pick the value of K at elbow point. Elbow
point refer to the point after which the change in WCSS is not
significant, or after which point the plot moves almost parallel to the
x-axis.

```{r, echo = TRUE}
data_for_clustering <- total_capture[, c("Total_CO2_capture", "file_id")]
```

```{r, echo = TRUE}
wcss <- sapply(1:10, function(k){
  kmeans(data_for_clustering, centers = k)$tot.withinss
})
```

Now let's take a look at the plot we get from this:

```{r}
elbow_plot <- data.frame(k = 1:10, wcss = wcss)
ggplot(elbow_plot, aes(x = k, y = wcss), bins = 10) + 
  geom_point() + 
  geom_line() + 
  labs(title = "Elbow Method for  Optimal k", 
       x = "Number of clusters (k)", 
       y = "Total Within-Cluster Sum of Squares (WCSS)")
```

From the plot above, 4 seems to be the elbow point, so let's use it as
the value of K.

```{r, fig.height=14, fig.width=12}
# set.seed(123) # for reproducibility

clusters <- kmeans(data_for_clustering, centers = 4)
# 
# Assign cluster labels back to the file_id
kmean_total_caputer <- total_capture %>%
  mutate(group = as.factor(clusters$cluster[match(file_id, data_for_clustering$file_id)]))

## Now that we have the clusters, let's get the mean for those groups 

group_mean <- kmean_total_caputer |>
  group_by(year, group) |>
  summarize(mean_CO2 = mean(Total_CO2_capture, na.rm = TRUE), .groups = 'drop')

plot.k.means.facet <- ggplot() +
  geom_line(data = kmean_total_caputer, aes(x = year, y = Total_CO2_capture, group = file_id, color = group), alpha = 0.2) +  
  geom_smooth(data = group_mean, aes(x = year, y = mean_CO2, group = group, color = group), size = 1.5) + 
  facet_wrap( ~ group) + 
  labs(title = "Total CO2 Capture group vise facet",
       x = "Year",
       y = "Total CO2 Capture (tonnes CO2/ha)") +
  theme_minimal() +
  theme(legend.position = "bottom")

plot.k.means <- ggplot() +
  geom_line(data = kmean_total_caputer, aes(x = year, y = Total_CO2_capture, group = file_id, color = group), alpha = 0.3) +
  labs(title = "Total CO2 Capture group vise",
       x = "Year",
       y = "Total CO2 Capture (tonnes CO2/ha)") +
  theme_minimal() +
  theme(legend.position = "none")

plot.all <- ggplot() +
  geom_smooth(data = group_mean, aes(x = year, y = mean_CO2, group = group, color = group), level = 0.95) + 
  labs(title = "Mean CO2 Capture group vise",
       x = "Year",
       y = "Mean CO2 Capture (tonnes CO2/ha)") +
  theme_minimal() +
  theme(legend.position = "none")

plot.k.means.facet / (plot.k.means + plot.all)
```

Let's also take a look at the groups created by physical meaning
\newpage

```{r}
get_group <- function(file_id) {
  if (file_id <= 18) {
    return(1)
  } else if (file_id <= 36) {
    return(2)
  } else if (file_id <= 63) {
    return(3)
  } else if (file_id <= 81) {
    return(4)
  } else if (file_id <= 99) {
    return(5)
  } else {
    return(6)
  }
}

phy_groups <- readxl::read_excel("groups_by_phy_meaning.xlsx")[, -3] 
phy_groups <- phy_groups |>
  mutate(group = sapply(file_id, get_group)) |>
  select(-"input_file")

phy_groups_total_capture <- merge(total_capture, phy_groups, key="file_id")

phy_groups_mean <- phy_groups_total_capture |>
  group_by(year, group) |>
  summarize(meanCO2 = mean(Total_CO2_capture, na.rm = TRUE), .groups = "drop")
```

### Plot from Physical Groups

We can also cluster the files based on their physical properties. That
means using the values from columns **Solution**(2 distinct values) and
**Temperature**(3 distinct values), we can get 6(2 x 3) different
clusters.

We can then take a look at the similarities between the k-means clusters
and the physical clusters.

```{r fig.width=12, fig.height=10}
plot.phy.facet <- ggplot() +
  geom_line(data = phy_groups_total_capture, aes(x=year, y=Total_CO2_capture, group=file_id, color=group), alpha=0.2)+
  geom_smooth(data = phy_groups_mean, aes(x=year, y=meanCO2, color=group), size = 1) + 
  facet_wrap( ~ group, scales = "free_y") + # Allowing for different scales on the y-axis
  labs(
    title = "CO2 Capture by Physical Group",
    x = "Year",
    y = "CO2 Capture (tonnes CO2/ha)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom") 

plot.phy.facet
```

### Comparisons for k-means and physical clusters

Since we have 6 different clusters for the *physical clustering*, let's
change our k-means clusters to 6 for the sake of comparison:

```{r echo=TRUE}
clusters <- kmeans(data_for_clustering, centers = 6)

kmean_total_caputer.revised <- total_capture %>%
  mutate(group = as.factor(clusters$cluster[match(file_id, data_for_clustering$file_id)]))

group_mean <- kmean_total_caputer.revised |>
  group_by(year, group) |>
  summarize(mean_CO2 = mean(Total_CO2_capture, na.rm = TRUE), .groups = 'drop')
```

```{r}
plot.k.means.revised.facet <- ggplot() +
  geom_line(data = kmean_total_caputer.revised, aes(x = year, y = Total_CO2_capture, group = file_id, color = group), alpha = 0.2) +  
  geom_smooth(data = group_mean, aes(x = year, y = mean_CO2, group = group, color = group), size = 1.5) + 
  facet_wrap( ~ group) + 
  labs(title = "Total CO2 Capture group vise facet",
       x = "Year",
       y = "Total CO2 Capture (tonnes CO2/ha)") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

\newpage

Now let's take a look at the side by side facet plot:

```{r fig.width=16, fig.height=20}
plots_k_means <- list()
plots_phy <- list()

for(i in 1:6) {
  # Filter the data for each group and create the plot for k-means revised
  plots_k_means[[i]] <- ggplot() +
    geom_line(data = subset(kmean_total_caputer.revised, group == i), aes(x = year, y = Total_CO2_capture, group = file_id, color = group), alpha = 0.2) +
    geom_smooth(data = subset(group_mean, group == i), aes(x = year, y = mean_CO2, group = group, color = group), size = 1.5) +
    labs(title = paste("Group", i, "Total CO2 Capture"), x = "Year", y = "Total CO2 Capture (tonnes CO2/ha)") +
    theme_minimal() +
    theme(legend.position = "none") 

  # Filter the data for each group and create the plot for physical groups
  plots_phy[[i]] <- ggplot() +
    geom_line(data = subset(phy_groups_total_capture, group == i), aes(x=year, y=Total_CO2_capture, group=file_id, color=group), alpha=0.2) +
    geom_smooth(data = subset(phy_groups_mean, group == i), aes(x=year, y=meanCO2, color=group), size = 1) +
    labs(title = paste("Group", i, "CO2 Capture by Physical Group"), x = "Year", y = "CO2 Capture (tonnes CO2/ha)") +
    theme_minimal() +
    theme(legend.position = "none") 
}

# Now combine the plots side by side for each group
paired_plots <- map2(plots_k_means, plots_phy, ~ .x + .y + plot_layout(guides = 'collect')) 

# Use `wrap_plots` to arrange all paired plots in the desired layout
final_plot <- wrap_plots(paired_plots, ncol = 2)

# Print the final combined plot
print(final_plot)
```


\newpage

We can see that although there might be some differences in the grouping number, but mostly the k-means clusters are identical to the ones we get through the physical clustering. 

Now let's take a look from these clusters what can we predict about the importance of different parameters. And take a look at what are the more important parameters for the prediction of the CO2 absorption levels. 

```{r}
write.csv(phy_groups_total_capture, "./phy_groups_total_capture.csv")
```


## Correlation 

```{r fig.width=14, fig.height=12}
pair.data <- phy_groups_total_capture |>
  select(c("Total_CO2_capture", "year", "Solution", "temp", "shifts"))
ggpairs(pair.data)
```